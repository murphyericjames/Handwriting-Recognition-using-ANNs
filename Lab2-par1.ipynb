{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find appropriate learning rate and momentum rate for given number of hidden units for Tanh and quadratic loss function\n",
    "library(h2o)\n",
    "localH2O<- h2o.init()\n",
    "\n",
    "#this function does not actually exist\n",
    "#h2o.addFunction(localH2O, function(x) { 1/(1+exp(-x)) }, \"Logsig\")\n",
    "\n",
    "#Import the data from the website repository, first name the path\n",
    "train_file <- \"http://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tra\"\n",
    "test_file <- \"http://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tes\"\n",
    "\n",
    "#give path to the importFile command in R\n",
    "train1 <- h2o.importFile(train_file)\n",
    "test <- h2o.importFile(test_file)\n",
    "\n",
    "#get summary of data\n",
    "#summary(train)\n",
    "#summary(test)\n",
    "\n",
    "#get a vector of the number of instances and the length of the feature vectors\n",
    "dtrain <- dim(train1)\n",
    "dtest <- dim(test)\n",
    "\n",
    "#split training data at random for a selection to train on and a selection to validate hyperparameters\n",
    "splits <- h2o.splitFrame(train1, c(0.8), seed=1385)\n",
    "train <- h2o.assign(splits[[1]], \"train.hex\")\n",
    "valid <- h2o.assign(splits[[2]], \"valid.hex\")\n",
    "\n",
    "#can do some initial data inspection using, C65 is the labeled category\n",
    "#par(mfrow=c(1,1))\n",
    "#plot(h2o.tabulate(train, \"C40\", \"C65\"))\n",
    "#plot(h2o.tabulate(train, \"C30\", \"C65\"))\n",
    "\n",
    "\n",
    "#treat vectors as integer categories(factors), and thus not factors\n",
    "train <- as.factor(train)\n",
    "valid <- as.factor(valid)\n",
    "test <- as.factor(test)\n",
    "\n",
    "#set the target and feature(predictor) vectors\n",
    "response <- \"C65\"\n",
    "predictors <- setdiff(names(train1), response)\n",
    "predictors\n",
    "\n",
    "#set parameters for the hidden layers search, with low learning rate, e.g. the 0.01\n",
    "#set number of  momentum rates to look at\n",
    "momrates <- c(0.0, 0.05, 0.1, 0.5, 0.9)\n",
    "#set number of rates to look at\n",
    "rates <- c(0.0001,0.005,0.01,0.02,0.05)\n",
    "\n",
    "#give a string index for all of these lists\n",
    "#choose hidden layers, by looping over a set of them\n",
    "#extract convergence rate and accuracy\n",
    "#do study on learning rate for both tanh, and Rectifier for the hyperparameters\n",
    "\n",
    "#give initial lists\n",
    "explist <- list()\n",
    "accuracylist <- list()\n",
    "vmselist <- list()\n",
    "trmselist <- list()\n",
    "stoplist <- list()\n",
    "\n",
    "count=1\n",
    "\n",
    "for (i in 1:length(momrates)){\n",
    "    for (j in 1:length(rates)){\n",
    "        #automatically uses softmax output\n",
    "        m1 <- h2o.deeplearning(\n",
    "            model_id=\"dl_model_first\", \n",
    "            training_frame=train, \n",
    "            validation_frame=valid,   ## validation dataset: used for scoring and early stopping\n",
    "            x=predictors,\n",
    "            y=response,\n",
    "            #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each\n",
    "            epochs=1,#000,                ##  controls stopping times\n",
    "            #variable_importances=T,    ## not enabled by default\n",
    "            distribution = \"multinomial\", ##  we have categorical data\n",
    "            standardize = T,  ## standardize the input data\n",
    "            activation = \"Tanh\",  ## may choose Tanh or Rectifier, i.e. ReLU. Logistic sigmoid not included\n",
    "            categorical_encoding=\"OneHotInternal\",  ## this ensures the use of the 1 of c encoding with \"OneHotInternal\"\n",
    "            loss = \"Quadratic\",  ## can be \"Quadratic\" or \"CrossEntropy\"\n",
    "            adaptive_rate = F, ##turn adaptive rate adjustments off\n",
    "            rate = rates[i], #the learning rate, start around 0.5, should be positive\n",
    "            #to reduce number of hyper parameters we will do this so that \n",
    "            momentum_start = momrates[j], #the momentum at the start, overall must be 0<\\alpha<1\n",
    "            momentum_ramp = 1, #the number of samples overwhich the ramp occurs\n",
    "            momentum_stable = momrates[j], #the stable momentum, should be again less than 1 and greater than 0\n",
    "            #train_samples_per_iteration = 0, #number of training samples per mapreduce iteraton, \n",
    "            #special vals 0 one epoch, -1 all available data, -2 autotuning\n",
    "            #want to disable early stopping\n",
    "            classification_stop = -1,\n",
    "            regression_stop = -1,\n",
    "            overwrite_with_best_model=FALSE,  #don't save the best model\n",
    "            #change to best hidden list\n",
    "            hidden=c(40,40)#unlist(hiddenlist[count])#c(50,50) ## hidden layers c(100,100) 2 hidden layers with 100 neurons each\n",
    "        )\n",
    "        \n",
    "        #find the convergence statistics for the \n",
    "        #find performance statistics i.e. accuracy for the training set\n",
    "        #m2 = h2o.performance(m1, newdata=test, train=FALSE, valid=FALSE, xval=FALSE)\n",
    "        Mat = h2o.confusionMatrix(m1, newdata=test, valid=FALSE)\n",
    "        #accuracy on the training case\n",
    "        accuracy = 1-tail(Mat$Error, n=1)\n",
    "        \n",
    "        #final mean squared error for the training and validation sets\n",
    "        vmse <- h2o.mse(m1, valid=TRUE, train=FALSE)\n",
    "        trmse <- h2o.mse(m1, valid=FALSE, train=TRUE)\n",
    "\n",
    "        #now fit the convergence with a power law\n",
    "        tr <- m1@model$scoring_history$training_rmse\n",
    "        v <- m1@model$scoring_history$validation_rmse\n",
    "        ep <- m1@model$scoring_history$epochs\n",
    "\n",
    "        fit <- lm(log(ep)~log(tr))\n",
    "        pow <- summary(fit)$coefficients[2,1]\n",
    "        exp <- 1/pow\n",
    "        \n",
    "        #put everything in a list\n",
    "        explist[[length(explist)+1]] <- exp\n",
    "        accuracylist[[length(accuracylist)+1]] <- accuracy\n",
    "        vmselist[[length(vmselist)+1]] <- vmse\n",
    "        trmselist[[length(trmselist)+1]] <- trmse\n",
    "        stoplist[[length(stoplist)+1]]  <- tail(ep, n=1)\n",
    "        count\n",
    "        count <- count+1\n",
    "        }}\n",
    "\n",
    "#plot the accuracy of everything\n",
    "acc <- unlist(accuracylist)\n",
    "Macc <- matrix(acc, nrow=length(layers), ncol=length(units), byrow = TRUE)\n",
    "#set up the plot\n",
    "plot(x=NULL,y=NULL, ylim=c(0.5,1.0), xlim=c(10,60), xlab = \"Hidden units\", ylab=\"Accuracy\", main =\"Classification Accuracy\")\n",
    "lines(rates, Macc[1,1:length(rates)], type = \"o\", col = \"red\")\n",
    "lines(rates, Macc[2,1:length(rates)], type = \"o\", col = \"blue\")\n",
    "lines(rates, Macc[3,1:length(rates)], type = \"o\", col = \"black\")\n",
    "lines(rates, Macc[4,1:length(rates)], type = \"o\", col = \"orange\")\n",
    "lines(rates, Macc[5,1:length(rates)], type = \"o\", col = \"green\")\n",
    "legend(35, 0.7, c(\"Mom-rate=0.0\", \"Mom-rate=0.05\",\"Mom-rate=0.1\",\"Mom-rate=0.5\",\"Mom-rate=0.9\"),lwd=c(2.5,2.5),col=c(\"red\",\"blue\",\"black\",\"orange\",\"green\"))\n",
    " \n",
    "#plot the convergence rate of it all\n",
    "expon <- unlist(explist)\n",
    "Mexp <- matrix(expon, nrow=length(layers), ncol=length(units), byrow = TRUE)\n",
    "#set up the plot\n",
    "plot(x=NULL,y=NULL, ylim=c(-2,0), xlim=c(0,0.05), xlab = \"Hidden units\", ylab=\"Accuracy\", main =\"Convergence Rate Exponent for the Training MSE\")\n",
    "lines(rates, Mexp[1,1:length(rates)], type = \"o\", col = \"red\")\n",
    "lines(rates, Mexp[2,1:length(rates)], type = \"o\", col = \"blue\")\n",
    "lines(rates, Mexp[3,1:length(rates)], type = \"o\", col = \"black\")\n",
    "lines(rates, Mexp[4,1:length(rates)], type = \"o\", col = \"orange\")\n",
    "lines(rates, Mexp[5,1:length(rates)], type = \"o\", col = \"green\")\n",
    "legend(40, -1.3, c(\"Mom-rate=0.0\", \"Mom-rate=0.05\",\"Mom-rate=0.1\",\"Mom-rate=0.5\",\"Mom-rate=0.9\"),lwd=c(2.5,2.5),col=c(\"red\",\"blue\",\"black\",\"orange\",\"green\"))\n",
    "        \n",
    "#plot the MSE for the validation case at the last iteration\n",
    "vmse2 <- unlist(vmselist)\n",
    "Mvmse <- matrix(vmse2, nrow=length(layers), ncol=length(units), byrow = TRUE)\n",
    "#set up the plot\n",
    "plot(x=NULL,y=NULL, ylim=c(0,0.5), xlim=c(0,0.05), xlab = \"Hidden units\", ylab=\"Accuracy\", main =\"MSE for the Validation Set\")\n",
    "lines(rates, Mvmse[1,1:length(rates)], type = \"o\", col = \"red\")\n",
    "lines(rates, Mvmse[2,1:length(rates)], type = \"o\", col = \"blue\")\n",
    "lines(rates, Mvmse[3,1:length(rates)], type = \"o\", col = \"black\")\n",
    "lines(rates, Mvmse[4,1:length(rates)], type = \"o\", col = \"orange\")\n",
    "lines(rates, Mvmse[5,1:length(rates)], type = \"o\", col = \"green\")\n",
    "legend(40, 0.35, c(\"Mom-rate=0.0\", \"Mom-rate=0.05\",\"Mom-rate=0.1\",\"Mom-rate=0.5\",\"Mom-rate=0.9\"),lwd=c(2.5,2.5),col=c(\"red\",\"blue\",\"black\",\"orange\",\"green\"))\n",
    "        \n",
    "#plot the MSE for the validation case at the last iteration\n",
    "stop <- unlist(stoplist)\n",
    "Mstop <- matrix(stop, nrow=length(layers), ncol=length(units), byrow = TRUE)\n",
    "#set up the plot\n",
    "plot(x=NULL,y=NULL, ylim=c(0,5), xlim=c(0,0.05), xlab = \"Hidden units\", ylab=\"Accuracy\", main =\"Early Stopping Time\")\n",
    "lines(rates, Mstop[1,1:length(rates)], type = \"o\", col = \"red\")\n",
    "lines(rates, Mstop[2,1:length(rates)], type = \"o\", col = \"blue\")\n",
    "lines(rates, Mstop[3,1:length(rates)], type = \"o\", col = \"black\")\n",
    "lines(rates, Mstop[4,1:length(rates)], type = \"o\", col = \"orange\")\n",
    "lines(rates, Mstop[5,1:length(rates)], type = \"o\", col = \"green\")\n",
    "legend(40, 0.35,c(\"Mom-rate=0.0\", \"Mom-rate=0.05\",\"Mom-rate=0.1\",\"Mom-rate=0.5\",\"Mom-rate=0.9\"),lwd=c(2.5,2.5),col=c(\"red\",\"blue\",\"black\",\"orange\",\"green\"))\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
